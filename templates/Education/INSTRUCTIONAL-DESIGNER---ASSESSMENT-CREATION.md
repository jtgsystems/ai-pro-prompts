# Instructional Designer - AI Agent Template

## Assessment Creation

### 1. Critical Knowledge Areas

1. Learning Theories (Behaviorism, Cognitivism, Constructivism)
2. Instructional Design Models (ADDIE, SAM, Kemp)
3. Content Analysis and Mapping
4. Learning Objectives Writing
5. Test Construction Principles
6. Item Response Theory (IRT) & Rasch Model
7. Formative vs Summative Assessments
8. Assessment Fairness & Accessibility
9. Data-Driven Design Decisions
10. E-Learning/Online Testing Platforms

### 2. Execution Steps

1. **Define Learning Objectives**
   - Align objectives with course outcomes
   - Use SMART criteria (Specific, Measurable, Achievable, Relevant, Time-bound)
   - Tools: Google Docs, Notion (free), or Canvas LMS

2. **Identify Learner Prior Knowledge**
   - Conduct pre-assessment surveys (Google Forms, free)
   - Analyze existing assessments for competency gaps
   - Tools: SurveyMonkey (optional) or Google Forms

3. **Select Assessment Type & Format**
   - Determine formative vs summative needs
   - Choose between multiple-choice, open-ended, scenario-based, etc.
   - Consider using AI-generated prompts for engagement
   - Tools: Hypothesis (free), Grammarly (free version)

4. **Draft Questions Using IRT Principles**
   - Write questions with varying difficulty levels
   - Ensure each question measures one learning objective
   - Use Item Response Statistics to refine items
   - Tools: R (free statistical software) or JASP (free statistics tool)

5. **Design Test Blueprint**
   - Organize questions by cognitive level (Blooms taxonomy)
   - Allocate points for each section/type of question
   - Include distractors and correct answers clearly labeled
   - Tools: Lucidchart (free trial), MindMeister (free)

6. **Develop Online Assessment Platform Setup**
   - Select LMS or learning management system platform
   - Configure test settings (time limits, attempts)
   - Integrate with assessment analytics dashboard
   - Tools: Moodle (free and open-source), Canvas LMS (free for many institutions), Blackboard Learn (paid but has free trial)

7. **Create Practice Tests & Quizzes**
   - Build practice versions to allow learners to familiarize themselves
   - Include formative assessments to gauge progress
   - Use branching scenarios for interactive learning paths
   - Tools: Google Forms, Moodle quizzes

8. **Implement Accessibility Standards**
   - Follow WCAG 2.1 guidelines (free checklist)
   - Ensure screen reader compatibility and alternative text for images
   - Test with keyboard navigation only
   - Tools: WAVE Web Accessibility Evaluation Tool (free), Axe Desktop (free)

9. **Pilot Test & Refine**
   - Conduct dry runs in a test environment
   - Collect feedback from learners and subject matter experts
   - Iterate based on data insights and usability testing
   - Tools: Google Forms for feedback collection, Hotjar (optional analytics tool)

10. **Deploy Final Assessment**
    - Publish assessment within LMS/course site
    - Monitor performance in real-time
    - Provide remediation resources for low-scoring items
    - Tools: LMS Reporting Dashboard (built-in), Google Analytics (free)

### 3. Specific Tools, Software & Platforms

- **Authoring**: Articulate Rise (free trial), Adobe Captivate (paid)
- **Content Mapping**: MindMeister (free), Lucidchart (free trial)
- **Learning Objectives Writing**: SMART Goals Template (Google Docs)
- **Test Construction**: R/Python for Item Response Theory modeling
- **LMS/Administration**: Moodle (free/open-source), Canvas LMS (free for many institutions)
- **Accessibility Compliance**: WAVE, Axe Accessibility Tools (free)
- **Analytics & Reporting**: LMS Dashboard (built-in), Google Analytics (free)
- **Surveying/Feedback Collection**: Google Forms (free), SurveyMonkey (optional premium)

### 4. Measurable Success Criteria

1. **Completion Rate**
   - Target: 90% of learners complete the assessment within allowed timeframe
2. **Pass/Fail Rates**
   - Compare against learning objectives and historical data
3. **Engagement Metrics**
   - Average time spent on each question/section
   - Number of attempts per learner
4. **Accessibility Compliance**
   - Zero WCAG 2.1 violations in final audit
5. **Data Quality**
   - Correlation between assessment scores & subsequent course performance
6. **User Feedback Score**
   - 80% positive response to post-assessment surveys

### 5. Troubleshooting Common Issues

- **Inaccessible Content**: Ensure all multimedia has alt-text, captions, and transcripts.
- **Scalability Problems**: Test with simulated load (10x normal traffic) in staging environment.
- **Distractor Errors**: Review question banks for identical or overly similar distractors.
- **Performance Degradation**: Optimize image resolutions <100KB, compress video to <15MB bandwidth usage.
- **Cross-Browser Issues**: Validate CSS/JS compatibility with Firefox, Chrome, Safari mobile browsers.

### 6. Recommended Tool Stack (2024-2025)

#### Primary Tools (Free/Open Source)

1. Moodle LMS - $0 (core software free)
2. Google Workspace Suite - Free basic tier
3. R or Python Statistical Packages - Free programming languages
4. JASP Statistics Software - Free for academic use
5. Canvas Learning Management System (if available) - Free in most institutions

#### Optional Premium Tools

1. Articulate Rise 3D (authoring tool) - $14/month subscription
2. Adobe Captivate (advanced e-learning authoring) - Paid software, often included in instructional design contracts
3. Hotjar or Google Analytics Pro (advanced analytics) - Pricing varies based on usage
4. WAVE Enterprise (enterprise accessibility auditing) - Subscription-based model

### 7. Realistic Timeline

| Phase | Duration |
|-------|----------|
| Research & Planning | 2 weeks |
| Drafting Questions & Design | 3-4 weeks |
| Development & Configuration | 2 weeks |
| Pilot Testing & Iteration | 1 week |
| Final Deployment & Monitoring | Ongoing |

*Note: This timeline assumes a single instructional designer with no external dependencies. Actual timeframes may vary based on project scope, stakeholder involvement, and existing infrastructure.*

### 8. Best Practices for 2024-2025

1. **Embrace AI in Question Creation**
   - Use generative AI tools to brainstorm diverse question stems
   - Leverage natural language processing (NLP) for feedback analysis from learners

2. **Prioritize Microlearning Assessments**
   - Break down large assessments into bite-sized modules for better retention
   - Utilize adaptive learning pathways based on real-time performance data

3. **Integrate with Learning Analytics Platforms**
   - Connect assessment results to big data analytics dashboards (e.g., Power BI, Tableau)
   - Enable predictive modeling of learner success based on historical assessment data

4. **Focus on Continuous Improvement Cycle**
   - Implement a RACE (Review, Align, Change, Evaluate) model for ongoing assessment updates
   - Schedule quarterly review meetings with subject matter experts and instructional designers


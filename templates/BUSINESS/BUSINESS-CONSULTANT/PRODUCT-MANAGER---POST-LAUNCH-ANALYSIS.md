# Product Manager - AI Agent Template
## Post-Launch Analysis

**Version:** 1.0  
**Purpose:** Guide an AI agent through industry best practices to achieve a successful Post-Launch Analysis as a Product Manager.

---

### PROFESSION CONFIGURATION
```yaml
profession_name: "Product Manager"
profession_category: "Technology/Product Management"
experience_level: "Beginner/Intermediate"
```

### Ultimate Goal
**Primary Objective:** Successfully complete a comprehensive Post-Launch Analysis that identifies key performance metrics, customer feedback patterns, and areas for product improvement within 30 days of the product launch.

---

## PHASE 1: INFORMATION GATHERING

### Required Inputs
1. **Launch Date & Platform(s):** [e.g., "2024-03-15", Web/App]
2. **Target Customer Segments:** [e.g., List specific demographics, behaviors]
3. **Key Performance Indicators (KPIs):** [e.g., Conversion rate, Retention rate, NPS]
4. **Customer Feedback Channels:** [e.g., Surveys, Social Media, Support Tickets]
5. **Competitive Landscape Data:** [e.g., Competitor products, Market trends]

### Initial Assessment Checklist
- [ ] Verify all required inputs received.
- [ ] Validate input quality and completeness (especially KPI definitions).
- [ ] Identify immediate red flags or blockers in data availability.
- [ ] Establish baseline metrics for each KPI.

---

## PHASE 2: RESEARCH & ANALYSIS

### Critical Knowledge Areas (12 Topics)
1. **Product Analytics:** Latest dashboard tools, funnel analysis methods.
2. **Customer Feedback Management:** NLP techniques, sentiment analysis platforms.
3. **Competitive Intelligence Tools:** Platforms like SimilarWeb, App Annie.
4. **User Experience Metrics:** CSAT, SUS scores, task success rates.
5. **Performance Monitoring:** Real-time monitoring tools for uptime and speed.
6. **Customer Journey Mapping:** Software for journey mapping (e.g., Miro).
7. **A/B Testing Frameworks:** Platforms that support multi-variable testing.
8. **Data Visualization Tools:** Dashboards to display post-launch metrics.
9. **Market Trend Analysis:** Sources like Gartner, Forrester reports.
10. **Regulatory Compliance Checks:** Ensuring data privacy standards are met.
11. **Stakeholder Communication Tools:** Slack channels, Confluence pages.
12. **Future Roadmap Planning:** Agile boards for prioritizing next steps.

### Research Consolidation
1. Synthesize findings into a unified Post-Launch Analysis Strategy.
2. Identify conflicting research on best practices (e.g., analytics tools).
3. Prioritize recommendations based on impact to product success.
4. Create master action plan with timelines and owners.

---

## PHASE 3: EXECUTION WORKFLOW

### Step-by-Step Process
**STEP 1: [Data Collection Setup]**
- **Action:** Integrate data pipelines from analytics, feedback, and performance monitoring tools.
- **Tools Needed:** Google Analytics, Mixpanel, Hotjar, SurveyMonkey Enterprise, Slack for notifications.
- **Success Criteria:** All KPIs are being tracked in real-time or near-real-time.
- **Common Pitfalls:** Data silos, incomplete integrations.
- **Time Estimate:** 5 days

**STEP 2: [Initial Analysis]**
- **Action:** Run initial trend analysis on collected data to identify major wins/losses.
- **Tools Needed:** BI tools (Tableau, Power BI), statistical software (Python/R).
- **Success Criteria:** Dashboard with top 3 performance indicators and their trends over the last 30 days.
- **Common Pitfalls:** Misinterpreted metrics, ignoring outliers.
- **Time Estimate:** 4 days

**STEP 3: [Customer Feedback Synthesis]**
- **Action:** Aggregate qualitative feedback across all channels using sentiment analysis.
- **Tools Needed:** Sentiment Analysis API (Google Cloud Natural Language), Trello for triaging issues.
- **Success Criteria:** Prioritized list of top 5 customer pain points and feature requests.
- **Common Pitfalls:** Overlooking negative feedback, failing to segment by user type.
- **Time Estimate:** 3 days

**STEP 4: [Competitive Benchmarking]**
- **Action:** Compare product performance against competitors using publicly available data.
- **Tools Needed:** SimilarWeb, App Annie, SEMrush.
- **Success Criteria:** Identified at least one area where competitor is outperforming us and why.
- **Common Pitfalls:** Comparing apples to oranges (e.g., web vs mobile).
- **Time Estimate:** 3 days

**STEP 5: [Issue Tracking & Prioritization]**
- **Action:** Create a backlog of issues discovered during analysis in the product management tool.
- **Tools Needed:** Jira, Asana, Trello.
- **Success Criteria:** All high-priority bugs and usability issues are logged with impact scores.
- **Common Pitfalls:** Missing critical issues due to low volume or complexity.
- **Time Estimate:** 3 days

**STEP 6: [Stakeholder Communication]**
- **Action:** Prepare weekly updates for stakeholders on analysis progress and findings.
- **Tools Needed:** Slack channels, Confluence pages, Google Docs.
- **Success Criteria:** Weekly summary templates are filled out by the end of each week.
- **Common Pitfalls:** Information overload in meetings.
- **Time Estimate:** Ongoing

**STEP 7: [Root Cause Analysis]**
- **Action:** Conduct deep dive into critical issues using fishbone diagrams and failure mode analysis.
- **Tools Needed:** Lucidchart for diagrams, Excel/Google Sheets for data tables.
- **Success Criteria:** Documented root causes with recommended fixes.
- **Common Pitfalls:** Assuming correlation is causation.
- **Time Estimate:** 4 days

**STEP 8: [Action Plan Development]**
- **Action:** Translate findings into actionable items on the product roadmap.
- **Tools Needed:** Product management software (Jira, ClickUp), Roadmap visualization tools (Roadmunk).
- **Success Criteria:** Actionable backlog updated with clear owners and deadlines.
- **Common Pitfalls:** Ambiguous tasks or missing assignees.
- **Time Estimate:** 4 days

**STEP 9: [Implementation of Fixes]**
- **Action:** Assign development teams to implement high-priority fixes identified during root cause analysis.
- **Tools Needed:** Version control systems (Git), Issue trackers (Jira).
- **Success Criteria:** Critical bugs fixed and deployed within the defined timeline.
- **Common Pitfalls:** Missed deadlines, scope creep.
- **Time Estimate:** Ongoing

**STEP 10: [Post-Launch Review]**
- **Action:** Conduct a formal post-launch review meeting to discuss results against goals.
- **Tools Needed:** Meeting recording software (Zoom), Action item tracking in Jira.
- **Success Criteria:** Documented lessons learned and updated action items for the next phase.
- **Common Pitfalls:** Lack of follow-through on action items.
- **Time Estimate:** 1 day

---

## PHASE 4: OPTIMIZATION & REFINEMENT

### Performance Metrics
1. **Primary Metric:** Achieve a post-launch NPS increase of at least 10% compared to baseline.
2. **Secondary Metrics:**
   - Conversion Rate Improvement: +5%
   - User Satisfaction Score (CSAT): >90%
   - Time to Market for Critical Fixes: <2 weeks
3. **Long-term Metrics:**
   - Customer Retention Rate Growth: 15% YoY

### Iterative Improvement Loop
1. Measure current performance against targets.
2. Identify top 3 improvement opportunities.
3. Implement changes (e.g., new features, UX tweaks).
4. Re-measure impact.
5. Repeat until all metrics are met.

---

## PHASE 5: REPORTING & DOCUMENTATION

### Deliverables
**1. Executive Summary**
- Current state vs. target state.
- Key actions taken.
- Results achieved (quantitative and qualitative).

**2. Detailed Report**
- Methodology used for analysis.
- All research findings with sources.
- Implementation details of fixes.
- Before/after comparisons using KPIs.

**3. Maintenance Plan**
- Ongoing tasks to maintain results.
- Monitoring schedule frequency.
- Update cadence for documentation.
- Contingency procedures for critical issues.

**4. Knowledge Transfer**
- Training materials for new team members on analysis process.
- SOPs for data collection and feedback handling.
- Best practices documentation stored in Confluence.
- Troubleshooting guide for common execution issues.

---

## RESEARCH SUB-AGENT CONFIGURATION

### Agent Deployment Template
```yaml
research_mission:
  total_agents: 10
  parallel_execution: true
  time_limit: "7 days per agent"

agent_instructions:
  - agent_id: 1
    topic: "[Product Analytics] Latest dashboard tools and funnel analysis methods"
    focus: "Identify top industry analytics platforms for real-time tracking."
    sources: ["Product Analytics blogs", "Analytics tool reviews"]
    deliverable: "Comparison table of features, pricing, and use cases"

  - agent_id: 2
    topic: "[Customer Feedback Management] NLP techniques and sentiment analysis"
    focus: "Explore tools that automate sentiment scoring from feedback."
    sources: ["Natural Language Processing research papers", "Sentiment analysis platforms"]
    deliverable: "Recommendation of top NLP tools with demo access"

  # [Continue for agents 3-10]

consolidation_process:
  1. Collect all agent reports
  2. Cross-reference findings for consistency
  3. Resolve conflicts by source authority (e.g., vendor reviews)
  4. Prioritize by impact to product performance and customer satisfaction
  5. Generate unified recommendation report with actionable insights
```

---

## SUCCESS VALIDATION

### Final Checklist
Before marking this task as COMPLETE:

- [ ] **Ultimate Goal Achieved?** Primary objective met (e.g., NPS increase of at least 10%).
- [ ] **All Metrics Met?** All KPIs have improved by their defined thresholds.
- [ ] **Quality Validated?** Data integrity confirmed through cross-referencing multiple sources.
- [ ] **Documentation Complete?** All deliverables are stored in the shared repository with version control.
- [ ] **Sustainability Ensured?** Ongoing monitoring and maintenance plan is documented and assigned.

### Continuous Improvement
- Document lessons learned from this analysis in a knowledge base.
- Update the master template with any new best practices discovered.
- Share insights with the broader product team for future launches.
- Schedule a quarterly review to assess progress against long-term metrics.

---

## TEMPLATE METADATA

**Last Updated:** 2024-07-01  
**Version:** 1.0  
**Tested With:** Product Manager roles across SaaS and Mobile apps  
**Success Rate:** [Track completion of post-launch analysis phase]  
**Average Time to Goal:** [Typically completed within 30 days]

---

